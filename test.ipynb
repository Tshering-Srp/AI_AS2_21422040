{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = tf.keras.models.load_model('my_face_recognition_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1386 (Conv2D)        (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_708 (MaxPooli  (None, 64, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1387 (Conv2D)        (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_709 (MaxPooli  (None, 32, 32, 64)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1388 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_710 (MaxPooli  (None, 16, 16, 128)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " flatten_236 (Flatten)       (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_831 (Dense)           (None, 128)               4194432   \n",
      "                                                                 \n",
      " dense_832 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_833 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_834 (Dense)           (None, 5)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,297,061\n",
      "Trainable params: 4,297,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# student_labels = {\n",
    "# 'shanti': 26,\n",
    "#  'shaurabh': 27,\n",
    "#  'amir': 4,\n",
    "#  'sungava': 28,\n",
    "#  'arpan': 5,\n",
    "#  'suraj': 29,\n",
    "#  'uman': 31,\n",
    "#  'bishesh': 8,\n",
    "#  'yogesh': 32,\n",
    "#  'dawa': 9,\n",
    "#  'bipana': 7,\n",
    "#  'dhanvir': 10,\n",
    "#  'dorje': 11,\n",
    "#  'hridaya': 12,\n",
    "#  'kritika': 13,\n",
    "#  'panas': 18,\n",
    "#  'sanjiv': 24,\n",
    "#  'milan': 14,\n",
    "#  'mirul': 15,\n",
    "#  'nabin': 16,\n",
    "#  'saugat': 25,\n",
    "#  'nishita': 17,\n",
    "#  'pawan': 19,\n",
    "#  'pratik': 20,\n",
    "#  'pushan': 21,\n",
    "#  'rabin': 22,\n",
    "#  'rupendra': 23,\n",
    "#  'bibek': 6,\n",
    "#  'aagya': 0,\n",
    "#  'adwait': 1,\n",
    "#  'alish': 2,\n",
    "#  'alishan': 3,\n",
    "#  'tshering': 30}\n",
    "\n",
    "# # Exchange keys and values\n",
    "# new_student_labels = {value: key for key, value in student_labels.items()}\n",
    "# new_student_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: 'tshering', 1: 'nischal', 2: 'pushan', 0: 'amir', 3: 'ritesh'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_labels = {'tshering': 4, 'nischal': 1, 'pushan': 2, 'amir': 0, 'ritesh': 3}\n",
    "\n",
    "# Exchange keys and values\n",
    "new_student_labels = {value: key for key, value in student_labels.items()}\n",
    "new_student_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ritesh'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_student_labels[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load and preprocess the image\n",
    "# from PIL import Image\n",
    "\n",
    "# image_path = \"tshering_6.jpg\" \n",
    "\n",
    "# img = image.load_img(image_path, target_size=(128, 128)) \n",
    "# img_array = image.img_to_array(img)\n",
    "# img_array = np.expand_dims(img_array, axis=0)\n",
    "# img_array /= 255.0\n",
    "\n",
    "# # Make predictions\n",
    "# predictions = model.predict(img_array)\n",
    "# # print(np.argmax(predictions))\n",
    "# print(predictions)\n",
    "\n",
    "# # Get the predicted class labels\n",
    "# predicted_class_indices = np.argmax(predictions, axis=1)\n",
    "\n",
    "# print(predicted_class_indices)\n",
    "# # Print the predicted class label\n",
    "# print(\"Predicted class:\", predicted_class_indices[0])\n",
    "\n",
    "# for key,val in student_labels.items():\n",
    "#     if val == predicted_class_indices[0]:\n",
    "#         print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 702ms/step\n",
      "[[0.07260533 0.0610338  0.21660392 0.0101853  0.63957167]]\n",
      "[4]\n",
      "Predicted class: 4\n"
     ]
    }
   ],
   "source": [
    "myImage = cv2.imread('tshering_6.jpg')\n",
    "resizedImage = cv2.resize(myImage, (128, 128))\n",
    "\n",
    "resizedImage = resizedImage.reshape(1, 128, 128, 3)\n",
    "\n",
    "img_array = resizedImage / 255.0\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "# print(np.argmax(predictions))\n",
    "print(predictions)\n",
    "\n",
    "# Get the predicted class labels\n",
    "predicted_class_indices = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(predicted_class_indices)\n",
    "# Print the predicted class label\n",
    "print(\"Predicted class:\", predicted_class_indices[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def live_attendance_management(new_student_labels):\n",
    "    \n",
    "#     attendance = {\n",
    "#         \"present\":[]\n",
    "#     }\n",
    "#     target_size = (128,128)\n",
    "#     # Open the video capture\n",
    "#     cap = cv2.VideoCapture(0) \n",
    "#     count = 0\n",
    "\n",
    "#     while True:\n",
    "#         # Capture frame-by-frame\n",
    "#         ret, frame = cap.read()\n",
    "\n",
    "#         # Resize the frame to the target size\n",
    "#         frame = cv2.resize(frame, target_size)\n",
    "\n",
    "#         # Preprocess the frame\n",
    "#         img_array = image.img_to_array(frame)\n",
    "#         img_array = np.expand_dims(img_array, axis=0)\n",
    "#         img_array /= 255.0\n",
    "\n",
    "#         # Make predictions on the preprocessed frame\n",
    "#         predictions = model.predict(img_array)\n",
    "#         predicted_class_index = np.argmax(predictions[0])\n",
    "        \n",
    "#         predicted_class_label = new_student_labels[predicted_class_index]\n",
    "\n",
    "#         if predicted_class_label not in attendance['present']:\n",
    "#             attendance['present'].append(predicted_class_label)\n",
    "\n",
    "#         # Display the predicted class on the frame\n",
    "#         cv2.putText(frame, predicted_class_label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "#         # Display the frame\n",
    "#         cv2.imshow('Live Prediction', frame)\n",
    "\n",
    "#         # Exit loop if 'q' is pressed\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "#     # Release the capture and close all windows\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "#     return attendance\n",
    "\n",
    "import random\n",
    "\n",
    "def combine_label(original_label):\n",
    "    # Combine the first two characters of the original label with a random number between 0 and 9\n",
    "    combined_label = original_label[:2] + str(random.randint(0, 9))\n",
    "    return combined_label\n",
    "\n",
    "def live_attendance_management(new_student_labels):\n",
    "\n",
    "    attendance = {\n",
    "        \"present\": []\n",
    "    }\n",
    "    target_size = (128, 128)\n",
    "    # Open the video capture\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    count = 0\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Resize the frame to the target size\n",
    "        frame = cv2.resize(frame, target_size)\n",
    "\n",
    "        # Preprocess the frame\n",
    "        img_array = image.img_to_array(frame)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array /= 255.0\n",
    "\n",
    "        # Make predictions on the preprocessed frame\n",
    "        predictions = model.predict(img_array)\n",
    "        predicted_class_index = np.argmax(predictions[0])\n",
    "\n",
    "        predicted_class_label = new_student_labels[predicted_class_index]\n",
    "\n",
    "        if predicted_class_label == \"tshering\":\n",
    "            # Display the predicted class on the frame\n",
    "            cv2.putText(frame, predicted_class_label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            if predicted_class_label not in attendance['present']:\n",
    "                attendance['present'].append(predicted_class_label)\n",
    "        else:\n",
    "            # Combine the original label with a partial label\n",
    "            partial_label = combine_label(predicted_class_label)\n",
    "            cv2.putText(frame, partial_label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            if partial_label not in attendance['present']:\n",
    "                attendance['present'].append(partial_label)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Live Prediction', frame)\n",
    "\n",
    "        # Exit loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the capture and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return attendance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    }
   ],
   "source": [
    "attendance = live_attendance_management(new_student_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>am1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>am2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>am6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>am4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>am9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  present\n",
       "0     am1\n",
       "1     am2\n",
       "2     am6\n",
       "3     am4\n",
       "4     am9"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attendance\n",
    "df = pd.DataFrame.from_dict(attendance)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_attendance_to_csv(sheet: pd.DataFrame,sheet_name: str) -> None :\n",
    "    # Create a DataFrame from the dictionary\n",
    "    df = pd.DataFrame.from_dict(sheet)\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(sheet_name,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_attendance_to_csv(attendance,\"attendance_sheet.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
